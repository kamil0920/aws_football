{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Re-load the dataset\n",
    "df_new = pd.read_csv('../data/transform/transformed_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cr = ['Unnamed: 0', 'match_api_id', 'season', 'stage', 'Unnamed: 0']\n",
    "df_numerical = df_new.drop(cr, axis=1)\n",
    "df_numerical.to_csv('../data/transform/df_numerical.csv')\n",
    "df_numerical.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(df, threshold=0.9, cols_to_remove=['date', 'away_team', 'home_team','home_team_goal',]):\n",
    "    \"\"\"\n",
    "    Removes features from the dataframe that have a correlation coefficient\n",
    "    higher than the specified threshold.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Dataframe with numerical features.\n",
    "    threshold (float): Threshold for high correlation.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (set of features to remove, reduced dataframe shape)\n",
    "    \"\"\"\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = df.drop(cols_to_remove, axis=1).corr()\n",
    "\n",
    "    # Find feature pairs with correlation greater than the threshold\n",
    "    # Interested in absolute value of correlation coefficient\n",
    "    highly_correlated_pairs = correlation_matrix.abs().unstack().sort_values(ascending=False)\n",
    "    highly_correlated_pairs = highly_correlated_pairs[highly_correlated_pairs >= threshold]\n",
    "    highly_correlated_pairs = highly_correlated_pairs[highly_correlated_pairs < 1]  # Remove self-correlation\n",
    "\n",
    "    # Since correlation is symmetric, we'll take one of each pair\n",
    "    # We will only take the first of the pair to remove.\n",
    "    features_to_remove = set([pair[0] for pair in highly_correlated_pairs.index])\n",
    "\n",
    "    print(features_to_remove)\n",
    "    df_ = df.drop(columns=features_to_remove)\n",
    "    print(df_.shape)\n",
    "    \n",
    "    return df_\n",
    "\n",
    "data_reduced = remove_highly_correlated_features(df_numerical)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the original dataset\n",
    "X = data_reduced.drop(['result_match', 'date', 'away_team', 'away_team_goal', 'home_team','home_team_goal', 'away_possession', 'home_shoton', 'home_possession', 'away_shoton', ], axis=1)\n",
    "y = data_reduced['result_match']\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_full = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the full feature set\n",
    "xgb_full.fit(X_train_full, y_train)\n",
    "\n",
    "# Predictions and evaluation on the full feature set\n",
    "y_pred_full = xgb_full.predict(X_test_full)\n",
    "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
    "\n",
    "accuracy_full"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature engineering: Aggregated player ratings for home and away teams\n",
    "player_rating_columns_home = [col for col in df_new.columns if 'home_player' in col]\n",
    "player_rating_columns_away = [col for col in df_new.columns if 'away_player' in col]\n",
    "\n",
    "# data_cleaned['avg_player_rating_home'] = data_cleaned[player_rating_columns_home].mean(axis=1)\n",
    "# data_cleaned['avg_player_rating_away'] = data_cleaned[player_rating_columns_away].mean(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_reduced['avg_player_rating_home'] = data_reduced[['player_rating_home_player_7','player_rating_home_player_8','player_rating_home_player_9',\n",
    "              'player_rating_home_player_10', 'player_rating_home_player_11']].mean(axis=1)\n",
    "\n",
    "data_reduced['avg_player_rating_away'] = data_reduced[['player_rating_away_player_7','player_rating_away_player_8','player_rating_away_player_9',\n",
    "              'player_rating_away_player_10', 'player_rating_away_player_11']].mean(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Boxplot for 'avg_player_rating_home' vs 'result_match'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='result_match', y='avg_player_rating_away', data=data_reduced)\n",
    "plt.title('Boxplot of Average Home Player Rating by Match Result')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Clear negative correaltion between result_match and avg_palyer_rating_away"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List of player positions for which we have ratings\n",
    "player_positions = range(7, 12)\n",
    "\n",
    "# Calculate the difference from the average for each player\n",
    "for position in player_positions:\n",
    "    home_player_col = f'player_rating_home_player_{position}'\n",
    "    away_player_col = f'player_rating_away_player_{position}'\n",
    "    \n",
    "    # Create new features for home and away players\n",
    "    data_reduced[f'diff_player_{position}'] = data_reduced[home_player_col] - data_reduced[away_player_col]\n",
    "    # data_reduced.drop([home_player_col, away_player_col], axis=1, inplace=True)\n",
    "\n",
    "# Display the dataframe to confirm the new features\n",
    "data_reduced.filter(like='diff_player').columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating new features based on the interactions\n",
    "data_reduced['new_feature_1'] = data_reduced['diff_player_9'] * data_reduced['points_diff']\n",
    "data_reduced['new_feature_2'] = data_reduced['avg_player_rating_home'] * data_reduced['points_diff']\n",
    "data_reduced['new_feature_3'] = data_reduced['diff_player_9'] + data_reduced['points_diff']\n",
    "data_reduced['new_feature_4'] = data_reduced['avg_player_rating_home'] + data_reduced['points_diff']\n",
    "data_reduced['new_feature_5'] = data_reduced['diff_player_8'] * data_reduced['diff_player_9'] * data_reduced['points_diff']\n",
    "data_reduced['new_feature_6'] = data_reduced['diff_player_9'] / (data_reduced['points_diff'] + 0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_rolling_averages(rolling_window_size, df, stat_columns):\n",
    "    \"\"\"\n",
    "    Calculate rolling averages for various statistics without including the current match.\n",
    "\n",
    "    Args:\n",
    "    - rolling_window_size (int): Number of previous matches to include in the rolling average.\n",
    "    - df (pd.DataFrame): The DataFrame containing the match data.\n",
    "    - stat_columns (dict): A dictionary with keys for each stat category (e.g., 'goals', 'possession', 'shots_on'),\n",
    "                           and values being another dictionary with 'home' and 'away' keys mapping to the respective columns.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with new rolling average columns added.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through each stat category\n",
    "    for stat, columns in stat_columns.items():\n",
    "        # Define new feature names for rolling features\n",
    "        home_feature_name = f'home_{stat}_rolling'\n",
    "        away_feature_name = f'away_{stat}_rolling'\n",
    "\n",
    "        # Calculate rolling averages for home and away statistics\n",
    "        for team_type in ['home', 'away']:\n",
    "            # Sort by team and date\n",
    "            df.sort_values(by=[f'{team_type}_team', 'date'], ascending=True, inplace=True)\n",
    "            \n",
    "            # Calculate rolling averages for the given stat\n",
    "            df[home_feature_name if team_type == 'home' else away_feature_name] = (\n",
    "                df.groupby(f'{team_type}_team')[columns[team_type]]\n",
    "                .apply(lambda x: x.shift().rolling(window=rolling_window_size).mean())\n",
    "                .reset_index(level=0, drop=True)\n",
    "            )\n",
    "            \n",
    "            # Calculate the means for rolling features\n",
    "            rolling_means = df.groupby(f'{team_type}_team')[home_feature_name if team_type == 'home' else away_feature_name].transform('mean')\n",
    "            \n",
    "            # Fill NaN values in rolling features with the team-specific means\n",
    "            df[home_feature_name if team_type == 'home' else away_feature_name] = (\n",
    "                df[home_feature_name if team_type == 'home' else away_feature_name].fillna(rolling_means)\n",
    "            )\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a range of window sizes to test\n",
    "window_sizes = [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15]\n",
    "\n",
    "# Define your statistical categories and their corresponding columns\n",
    "stat_columns = {\n",
    "    'goals': {\n",
    "        'home': 'home_team_goal',\n",
    "        'away': 'away_team_goal'\n",
    "    },\n",
    "    'possession': {\n",
    "        'home': 'home_possession',\n",
    "        'away': 'away_possession'\n",
    "    },\n",
    "    'shots_on': {\n",
    "        'home': 'home_shoton',\n",
    "        'away': 'away_shoton'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Placeholder for best score and corresponding window size\n",
    "best_score = -float('inf')\n",
    "best_window_size = None\n",
    "\n",
    "# Iterate over window sizes to find the best one\n",
    "for window_size in window_sizes:\n",
    "    # Calculate rolling averages using the current window size\n",
    "    df_with_rolling = calculate_rolling_averages(window_size, data_reduced.copy(), stat_columns)\n",
    "\n",
    "    df_with_rolling = df_with_rolling.drop(['date', 'away_team', 'away_team_goal', 'home_team','home_team_goal', 'away_possession', 'home_shoton', 'home_possession', 'away_shoton'], axis=1)\n",
    "    \n",
    "    # Extract features and target for model training\n",
    "    X = df_with_rolling.drop(['result_match'], axis=1)\n",
    "    y = df_with_rolling['result_match']\n",
    "    \n",
    "    # Define your model\n",
    "    model = XGBClassifier(random_state=42)  # Use your actual model here\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model, X, y, cv=2, scoring='accuracy')  # Change scoring method as needed\n",
    "    \n",
    "    # Calculate the mean score\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    # Update best score and window size if current score is better\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_window_size = window_size\n",
    "\n",
    "# best_window_size now holds the size of the window that gave the best performance\n",
    "print(f\"Best window size: {best_window_size} with score: {best_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_rolling = calculate_rolling_averages(best_window_size, df=data_reduced.copy(), stat_columns=stat_columns)\n",
    "df_with_rolling = df_with_rolling.drop(['date', 'away_team', 'away_team_goal', 'home_team','home_team_goal', 'away_possession', 'home_shoton', 'home_possession', 'away_shoton'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the original dataset\n",
    "X = df_with_rolling.drop('result_match', axis=1)\n",
    "y = df_with_rolling['result_match']\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_full = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the full feature set\n",
    "xgb_full.fit(X_train_full, y_train)\n",
    "\n",
    "# Predictions and evaluation on the full feature set\n",
    "y_pred_full = xgb_full.predict(X_test_full)\n",
    "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
    "\n",
    "accuracy_full"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_rolling.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df_with_rolling.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assuming 'df' is your original DataFrame\n",
    "\n",
    "# Creating difference features\n",
    "df['goal_difference_rolling'] = df['home_goals_rolling'] - df['away_goals_rolling']\n",
    "df['possession_difference_rolling'] = df['home_possession_rolling'] - df['away_possession_rolling']\n",
    "df['shots_on_target_difference_rolling'] = df['home_shots_on_rolling'] - df['away_shots_on_rolling']\n",
    "\n",
    "# Creating ratio features (adding 1 to the denominator to avoid division by zero)\n",
    "df['goals_ratio_rolling'] = df['home_goals_rolling'] / (df['away_goals_rolling'] + 1)\n",
    "df['possession_ratio_rolling'] = df['home_possession_rolling'] / (df['away_possession_rolling'] + 1)\n",
    "df['shots_on_target_ratio_rolling'] = df['home_shots_on_rolling'] / (df['away_shots_on_rolling'] + 1)\n",
    "\n",
    "# Checking the correlation of the new features with the target variable\n",
    "correlations = df[['goal_difference_rolling', 'possession_difference_rolling', \n",
    "                   'shots_on_target_difference_rolling', 'goals_ratio_rolling', \n",
    "                   'possession_ratio_rolling', 'shots_on_target_ratio_rolling', \n",
    "                   'result_match']].corr()\n",
    "\n",
    "# Focusing on the correlation with the target variable 'result_match'\n",
    "correlations_result_match = correlations['result_match']\n",
    "\n",
    "# Extracting the correlation values (excluding the last one as it is the correlation of 'result_match' with itself)\n",
    "correlation_values = correlations_result_match[:-1]\n",
    "\n",
    "# Creating a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlation_values.plot(kind='bar', color='skyblue')\n",
    "plt.title('Correlation of New Features with Match Result')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.axhline(y=0, color='k', linestyle='--')  # Adds a horizontal line at y=0 for reference\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Positive correlations are shown by bars extending above the horizontal line (y=0), \n",
    "# indicating that an increase in these features is associated with higher values of 'result_match'.\n",
    "\n",
    "# Negative correlations, shown by bars below the line, \n",
    "# suggest that an increase in these features is associated with lower values of 'result_match'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the Pearson correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Extract the correlations with the target variable 'result_match'\n",
    "correlations_with_target = correlation_matrix['result_match'].sort_values(ascending=False)\n",
    "\n",
    "correlations_with_target\n",
    "\n",
    "# Select the top 5 positively correlated and top 5 negatively correlated features (excluding the target itself)\n",
    "top_positive_correlated_features = correlations_with_target.index[1:6].tolist()\n",
    "top_negative_correlated_features = correlations_with_target.index[-5:].tolist()\n",
    "selected_features = top_positive_correlated_features + top_negative_correlated_features\n",
    "\n",
    "# Create a new dataframe with the selected features and the target variable\n",
    "selected_data = df[selected_features + ['result_match']]\n",
    "\n",
    "# Create a heatmap for the selected features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(selected_data.corr(), annot=True, fmt=\".2f\", cmap='viridis')\n",
    "plt.title('Heatmap of Selected Feature Correlations')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ = remove_highly_correlated_features(df, 0.98, [])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Splitting the original dataset\n",
    "X = df_.drop('result_match', axis=1)\n",
    "y = df_['result_match']\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_full = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the full feature set\n",
    "xgb_full.fit(X_train_full, y_train)\n",
    "\n",
    "# Predictions and evaluation on the full feature set\n",
    "y_pred_full = xgb_full.predict(X_test_full)\n",
    "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
    "\n",
    "accuracy_full"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"../data/transform/\"\n",
    "filename= \"df_engineered.csv\"\n",
    "\n",
    "full_path = os.path.join(output_dir, filename)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "df.to_csv(full_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}