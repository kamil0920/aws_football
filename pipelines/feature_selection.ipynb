{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Re-load the dataset\n",
    "df = pd.read_csv('../data/transform/df_feature_eng.csv')\n",
    "df_ = pd.read_csv('../data/transform/df_more_features.csv')\n",
    "\n",
    "df.drop(['Unnamed: 0', 'player_rating_home_player_7', 'player_rating_home_player_8',\n",
    "       'player_rating_home_player_9', 'player_rating_home_player_10',\n",
    "       'player_rating_home_player_11', 'player_rating_away_player_7',\n",
    "       'player_rating_away_player_8', 'player_rating_away_player_9',\n",
    "       'player_rating_away_player_10', 'player_rating_away_player_11',], axis=1, inplace=True)\n",
    "df_.drop(['Unnamed: 0', 'player_rating_home_player_7', 'player_rating_home_player_8',\n",
    "       'player_rating_home_player_9', 'player_rating_home_player_10',\n",
    "       'player_rating_home_player_11', 'player_rating_away_player_7',\n",
    "       'player_rating_away_player_8', 'player_rating_away_player_9',\n",
    "       'player_rating_away_player_10', 'player_rating_away_player_11',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3040, 33)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m k_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m6\u001B[39m, X_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m2\u001B[39m)  \u001B[38;5;66;03m# Testing different numbers of features\u001B[39;00m\n\u001B[0;32m     10\u001B[0m filter_accuracies \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 12\u001B[0m \u001B[43mselected_features\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m k_values:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;66;03m# Select top k features\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     selector \u001B[38;5;241m=\u001B[39m SelectKBest(f_classif, k\u001B[38;5;241m=\u001B[39mk)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'selected_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Separating features and target variable\n",
    "X = df.drop('result_match', axis=1)\n",
    "y = df['result_match']\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Filter Method: Selecting features using ANOVA F-test\n",
    "k_values = range(6, X_train.shape[1], 2)  # Testing different numbers of features\n",
    "filter_accuracies = []\n",
    "\n",
    "selected_features\n",
    "\n",
    "for k in k_values:\n",
    "    # Select top k features\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    # Train XGBoost classifier\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    filter_accuracies.append(accuracy)\n",
    "    selected_features = (selector.get_support())\n",
    "\n",
    "# Plotting the results\n",
    "plt.plot(k_values, filter_accuracies, marker='o', label='Filter Method (ANOVA F-test)')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Filter Method Feature Selection')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of features with the best accuracy\n",
    "best_k = k_values[filter_accuracies.index(max(filter_accuracies))]\n",
    "\n",
    "# Re-run the selection process for the best k\n",
    "selector = SelectKBest(f_classif, k=best_k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Retrieve the selected feature names\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "\n",
    "print(\"Selected features for k =\", best_k, \":\\n\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate the target variable and features\n",
    "X = df[selected_features]\n",
    "y = df['result_match']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "rfecv = RFECV(estimator=xgb, step=1, scoring='accuracy')\n",
    "# Run RFECV on the smaller subset\n",
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Assuming rfecv is your fitted RFECV object\n",
    "optimal_features = rfecv.n_features_\n",
    "cv_scores = rfecv.cv_results_['mean_test_score'] \n",
    "feature_rankings = rfecv.ranking_\n",
    "\n",
    "print(f\"Optimal number of features: {optimal_features}\")\n",
    "\n",
    "# Identify and print the most important features\n",
    "important_features = X.columns[rfecv.support_]\n",
    "print(f\"Most important features:\\n{important_features}\")\n",
    "\n",
    "# Plotting the CV Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross-validation score (accuracy)\")\n",
    "plt.plot(range(1, len(cv_scores) + 1), cv_scores)\n",
    "plt.title(\"RFECV - Optimal Number of Features\")\n",
    "plt.show()\n",
    "\n",
    "# Plotting feature rankings\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x=X.columns, y=feature_rankings)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Ranking\")\n",
    "plt.title(\"Feature Rankings\")\n",
    "plt.xticks(rotation=90)  # Rotate feature names for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the original dataset\n",
    "X = df[selected_features]\n",
    "y = df['result_match']\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_full = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the full feature set\n",
    "xgb_full.fit(X_train_full, y_train)\n",
    "\n",
    "# Predictions and evaluation on the full feature set\n",
    "y_pred_full = xgb_full.predict(X_test_full)\n",
    "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
    "\n",
    "accuracy_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import xgbfir\n",
    "\n",
    "xgbfir.saveXgbFI(xgb_full, feature_names=X_train.columns, OutputXlsxFile='fir.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = 'fir.xlsx'\n",
    "fir = pd.read_excel(file_path)\n",
    "\n",
    "# Extracting top features based on different metrics\n",
    "top_gain_features = fir.sort_values(by='Gain', ascending=False).head(10)\n",
    "top_fscore_features = fir.sort_values(by='FScore', ascending=False).head(10)\n",
    "top_wfscore_features = fir.sort_values(by='wFScore', ascending=False).head(10)\n",
    "top_avg_gain_features = fir.sort_values(by='Average Gain', ascending=False).head(10)\n",
    "top_expected_gain_features = fir.sort_values(by='Expected Gain', ascending=False).head(10)\n",
    "\n",
    "# Displaying the top features\n",
    "top_features_summary = {\n",
    "    \"Top Features by Gain\": top_gain_features['Interaction'].values,\n",
    "    \"Top Features by FScore\": top_fscore_features['Interaction'].values,\n",
    "    \"Top Features by wFScore\": top_wfscore_features['Interaction'].values,\n",
    "    \"Top Features by Average Gain\": top_avg_gain_features['Interaction'].values,\n",
    "    \"Top Features by Expected Gain\": top_expected_gain_features['Interaction'].values\n",
    "}\n",
    "\n",
    "top_features_summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the data from the \"Interaction Depth 1\" and \"Interaction Depth 2\" sheets\n",
    "interaction_depth_1 = pd.read_excel(file_path, sheet_name='Interaction Depth 1')\n",
    "interaction_depth_2 = pd.read_excel(file_path, sheet_name='Interaction Depth 2')\n",
    "\n",
    "# Display the first few rows of each sheet to understand their structure\n",
    "interaction_depth_1_head = interaction_depth_1.head(10)\n",
    "interaction_depth_2_head = interaction_depth_2.head(10)\n",
    "\n",
    "interaction_depth_1_head"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interaction_depth_2_head"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_depth_2_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3040, 179)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Score: 0.46191665512331187\n",
      "Best number of features: 50\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'result_match' is the target variable\n",
    "X = df.drop(['result_match'], axis=1)\n",
    "y = df['result_match']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a range for n_features_to_select\n",
    "feature_range = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 179] # Adjust this based on your dataset size and computational capacity\n",
    "\n",
    "best_score = 0\n",
    "best_n_features = 0\n",
    "\n",
    "# Iterate over the range\n",
    "for n_features in feature_range:\n",
    "    # Create a Decision Tree Classifier (can be replaced with another model for actual use)\n",
    "    model = XGBClassifier(random_state=42)\n",
    "\n",
    "    # Create the RFE model and select n features\n",
    "    rfe = RFE(estimator=model, n_features_to_select=n_features)\n",
    "    rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Transform the training and testing sets\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "    # Train the model on the reduced dataset\n",
    "    model.fit(X_train_rfe, y_train)\n",
    "\n",
    "    # Make predictions and evaluate using F1 score\n",
    "    y_pred = model.predict(X_test_rfe)\n",
    "    score = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Compare and store the best score and corresponding number of features\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n_features = n_features\n",
    "\n",
    "print(f\"Best F1 Score: {best_score}\")\n",
    "print(f\"Best number of features: {best_n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}