{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T15:39:02.040630Z",
     "start_time": "2024-03-06T15:39:01.794340900Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from hyperopt import hp, pyll\n",
    "# \n",
    "# uniform_vals = [pyll.stochastic.sample(hp.uniform('max_ctr_complexity', 0, 8))\n",
    "#                 for _ in range(10_000)]\n",
    "# fig, ax = plt.subplots(figsize=(8, 4))\n",
    "# ax.hist(uniform_vals)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:39:02.071627500Z",
     "start_time": "2024-03-06T15:39:02.042627400Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, X_val, y_train, y_val):\n",
    "    cat_cols = X_train.select_dtypes(exclude=['number']).columns.to_list()\n",
    "    \n",
    "    model = CatBoostClassifier(random_seed=42,iterations=500,early_stopping_rounds=75,eval_metric='F1')\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], use_best_model=True, cat_features=cat_cols, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "\n",
    "def handle_nan(X_train, X_val):\n",
    "    cat_cols = X_train.select_dtypes(exclude=['number']).columns.to_list()\n",
    "    num_cols = X_train.select_dtypes(include='number').columns\n",
    "\n",
    "    # Impute numerical columns\n",
    "    imputer = IterativeImputer(initial_strategy='most_frequent', max_iter=5, n_nearest_features=4)\n",
    "    X_train_num = pd.DataFrame(imputer.fit_transform(X_train[num_cols]), columns=num_cols, index=X_train.index)\n",
    "    X_val_num = pd.DataFrame(imputer.transform(X_val[num_cols]), columns=num_cols, index=X_val.index)\n",
    "\n",
    "    # Handle categorical columns\n",
    "    for column in cat_cols:\n",
    "        # Add 'Missing' category\n",
    "        X_train[column] = X_train[column].cat.add_categories('Missing')\n",
    "        X_val[column] = X_val[column].cat.add_categories('Missing')\n",
    "\n",
    "        # Fill NaN values with 'Missing'\n",
    "        X_train[column] = X_train[column].fillna('Missing')\n",
    "        X_val[column] = X_val[column].fillna('Missing')\n",
    "\n",
    "    # Concatenate numerical and categorical dataframes\n",
    "    X_train_processed = pd.concat([X_train_num, X_train[cat_cols]], axis=1)\n",
    "    X_val_processed = pd.concat([X_val_num, X_val[cat_cols]], axis=1)\n",
    "\n",
    "    return X_train_processed, X_val_processed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:39:02.075626600Z",
     "start_time": "2024-03-06T15:39:02.062627Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from typing import Any, Dict, Union\n",
    "\n",
    "\n",
    "def evaluate_model_opt(X_train, X_val, y_train, y_val, space):\n",
    "    cat_cols = X_train.select_dtypes(exclude=['number']).columns.to_list()\n",
    "    model = CatBoostClassifier(**space, early_stopping_rounds=75)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=0,\n",
    "        cat_features=cat_cols,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Return the weighted F1 score and the model\n",
    "    return f1_score(y_val, y_pred), model\n",
    "\n",
    "\n",
    "def hyperparameter_tuning(space: Dict[str, Union[float, int]],\n",
    "                          X_train: pd.DataFrame, y_train: pd.Series,\n",
    "                          X_val: pd.DataFrame, y_val: pd.Series) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning for an XGBoost classifier.\n",
    "    \n",
    "    This function takes a dictionary of hyperparameters, training\n",
    "    and test data, and an optional value for early stopping rounds,\n",
    "    and returns a dictionary with the loss and model resulting from\n",
    "    the tuning process. The model is trained using the training\n",
    "    data and evaluated on the test data. The loss is computed as\n",
    "    the negative of the accuracy score.\n",
    "    Parameters\n",
    "    ----------\n",
    "    space : Dict[str, Union[float, int]]\n",
    "        A dictionary of hyperparameters for the XGBoost classifier.\n",
    "    X_train : pd.DataFrame\n",
    "        The training data.\n",
    "    y_train : pd.Series\n",
    "        The training target.\n",
    "    X_test : pd.DataFrame\n",
    "        The test data.\n",
    "    y_test : pd.Series\n",
    "        The test target.\n",
    "    early_stopping_rounds : int, optional\n",
    "        The number of early stopping rounds to use. The default value is 50.\n",
    "    metric : callable\n",
    "        Metric to maximize. Default is accuracy\n",
    "        Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        A dictionary with the loss and model resulting from the\n",
    "        tuning process. The loss is a float, and the model is an\n",
    "        XGBoost classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    int_vals = ['depth']\n",
    "    space = {k: (int(val) if k in int_vals else val) for k, val in space.items()}\n",
    "    score, model = evaluate_model_opt(X_train, X_val, y_train, y_val, space)\n",
    "    return {'loss': -score, 'status': STATUS_OK, 'model': model}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:39:02.513233Z",
     "start_time": "2024-03-06T15:39:02.076627300Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T15:39:02.529234900Z",
     "start_time": "2024-03-06T15:39:02.514235400Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Sequence\n",
    "\n",
    "\n",
    "def trial2df(trial: Sequence[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a Trial object (sequence of trial dictionaries)\n",
    "    to a Pandas DataFrame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial : List[Dict[str, Any]]\n",
    "    A list of trial dictionaries.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    A DataFrame with columns for the loss, trial id, and\n",
    "    values from each trial dictionary.\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    for t in trial:\n",
    "        result = t['result']\n",
    "        misc = t['misc']\n",
    "        val = {k: (v[0] if isinstance(v, list) else v)\n",
    "               for k, v in misc['vals'].items()\n",
    "               }\n",
    "        val['loss'] = result['loss']\n",
    "        val['tid'] = t['tid']\n",
    "        vals.append(val)\n",
    "    return pd.DataFrame(vals)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def jitter(df: pd.DataFrame, col: str, amount: float = 1) -> pd.Series:\n",
    "    \"\"\"\n",
    "        Add random noise to the values in a Pandas DataFrame column.\n",
    "        This function adds random noise to the values in a specified\n",
    "        column of a Pandas DataFrame. The noise is uniform random\n",
    "        noise with a range of `amount` centered around zero. The\n",
    "        function returns a Pandas Series with the jittered values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "        The input DataFrame.\n",
    "        col : str\n",
    "        The name of the column to jitter.\n",
    "        amount : float, optional\n",
    "        The range of the noise to add. The default value is 1.\n",
    "        Returns\n",
    "        -------\n",
    "        pd.Series\n",
    "        A Pandas Series with the jittered values.\n",
    "    \"\"\"\n",
    "    vals = np.random.uniform(low=-amount / 2, high=amount / 2,\n",
    "                             size=df.shape[0])\n",
    "    return df[col] + vals\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    (hyper2hr\n",
    "     .assign(max_depth=lambda df: jitter(df, 'depth', amount=.8))\n",
    "     .plot.scatter(x='max_depth', y='loss', alpha=.1, color='purple', ax=ax)\n",
    "     )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:39:02.554231Z",
     "start_time": "2024-03-06T15:39:02.530235200Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:39:04.048450200Z",
     "start_time": "2024-03-06T15:39:02.547231200Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['stage'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m X \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/new_features/df_.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m y \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/new_features/y.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m X\u001B[38;5;241m.\u001B[39mfilter(like\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_binned\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m     10\u001B[0m     X[col] \u001B[38;5;241m=\u001B[39m X[col]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py10\\lib\\site-packages\\pandas\\core\\frame.py:5347\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   5199\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(\n\u001B[0;32m   5200\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   5201\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5208\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   5209\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5210\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5211\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[0;32m   5212\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5345\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[0;32m   5346\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 5347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5348\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5349\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5350\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5351\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5352\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5353\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5354\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5355\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py10\\lib\\site-packages\\pandas\\core\\generic.py:4711\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   4709\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m   4710\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 4711\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4713\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[0;32m   4714\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py10\\lib\\site-packages\\pandas\\core\\generic.py:4753\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[1;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[0;32m   4751\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m   4752\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 4753\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4754\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[0;32m   4756\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[0;32m   4757\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py10\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001B[0m, in \u001B[0;36mIndex.drop\u001B[1;34m(self, labels, errors)\u001B[0m\n\u001B[0;32m   6990\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m   6991\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 6992\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6993\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[0;32m   6994\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['stage'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# X = pd.read_csv('../data/binned/df.csv')\n",
    "# y = pd.read_csv('../data/binned/y.csv')\n",
    "\n",
    "X = pd.read_csv('../data/new_features/df_.csv')\n",
    "y = pd.read_csv('../data/new_features/y.csv')\n",
    "\n",
    "for col in X.filter(like='_binned').columns:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "X.filter(like='_binned').info()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val = handle_nan(X_train, X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.042447600Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.044449800Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "evaluate_model(X_train, X_val, y_train, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.046449800Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.047449900Z"
    }
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    'depth': hp.quniform('depth', 8, 15, 1),\n",
    "    'bagging_temperature': hp.loguniform('bagging_temperature', np.log(0.75), np.log(0.95)),\n",
    "    'rsm': hp.loguniform('rsm', np.log(0.75), np.log(0.95)),\n",
    "    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 1, 10),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'iterations': 50,\n",
    "    'max_ctr_complexity': hp.randint('max_ctr_complexity', 0, 8),\n",
    "    # 'boosting_type': hp.choice('boosting_type', ['Ordered', 'Plain']),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "tuned_params = fmin(fn=lambda space: hyperparameter_tuning(space, X_train, y_train, X_val, y_val),\n",
    "            space=options,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=200,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best Hyperparameters:\", tuned_params)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tuned_params = {'bagging_temperature': 0.8782622322892651, 'depth': 12.0, 'l2_leaf_reg': 3.449275895229593, 'learning_rate': 0.054678015156771904, 'max_ctr_complexity': 5, 'rsm': 0.8534565882197943}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:39:04.050449900Z",
     "start_time": "2024-03-06T15:39:04.049449900Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.051449600Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper2hr = trial2df(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.052449700Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper2hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.054449800Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.heatmap(hyper2hr.corr(method='spearman'),\n",
    "            annot=True, fmt='.2f', vmin=-1, vmax=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "(hyper2hr\n",
    " .plot.scatter(x='learning_rate', y='loss', alpha=.1, color='purple', ax=ax)\n",
    " )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.056450200Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This makes it quite clear that the algorithm spent a good amount of time at depth 10.\n",
    "# If we want to get even fancier, we can color this by trial attempt. The later attempts are\n",
    "# represented by the yellow color.\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "(hyper2hr\n",
    " .assign(max_depth=lambda df: jitter(df, 'depth', amount=.8))\n",
    " .plot.scatter(x='max_depth', y='loss', alpha=.5,\n",
    "               color='yellow', cmap='viridis', ax=ax)\n",
    " )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.057450100Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "f1, cat_tune =evaluate_model_opt(X_train, X_val, y_train, y_val, tuned_params)\n",
    "print(f'result: {f1}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.058450200Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cat_cols = X_train.select_dtypes(exclude='number').columns.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.059449900Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cat_clf = CatBoostClassifier(early_stopping_rounds=75)\n",
    "\n",
    "cat_clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=0,\n",
    "    cat_features=cat_cols,\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "y_pred_clf = cat_clf.predict(X_val)\n",
    "\n",
    "f1_score(y_val, y_pred_clf)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T15:39:04.066447100Z",
     "start_time": "2024-03-06T15:39:04.060449700Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_val, y_pred=cat_tune.predict(X_val), target_names=['Home Win', 'Home not win']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.062450100Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "metrics.RocCurveDisplay.from_estimator(cat_tune, X_val, y_val, ax=ax)\n",
    "\n",
    "metrics.RocCurveDisplay.from_estimator(cat_clf, X_val, y_val, ax=ax, label='default')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.063449600Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-06T15:39:04.064449800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
